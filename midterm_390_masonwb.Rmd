---
title: Probability of mortality of critically ill cancer patients at 72 h of intensive
  care unit (ICU) management
author: "Mason Boyles"
date: "2024-10-24"
output: pdf_document
fontsize: 12pt
---




# Introduction

An Intensive Care Unit (ICU) is a specialized hospital ward that is responsible for receiving patients who require critical care and constant monitoring. This can be because a patient recently received complex treatments such as chemotherapy or surgery and they have complications such as organ failure or it could also be for end-of-life care. Because of this, ICUs require advanced medical equipment and highly trained healthcare professionals which can lead to a shortage in availability, especially in peak periods or areas of high demand. In fact, the average hospital's ICU was around 90% full with 113 hospitals at or above 100% in December 2020, during the Covid pandemic (McCarthy and Richter). This shortage of ICU beds can lead to a variety of impacts. The first of which being that not everyone is always able to receive the care they may require, which leaves hospitals with the complicated task of prioritizing some patients over others. In addition, it can stretch resources thin and lead to lower quality care for all people in the ICU when capacity is above 100%.

This leads me to the topic of my paper, predicting the probability of mortality of critically ill cancer patients. The goal of the paper was to develop and validate a model that will predict the mortality of patients after 72 hours of ICU management using an inception cohort study performed at four ICUs of academic medical centers in the United States. In total, it used 827 patients as data to develop multiple logistic regression models and then validated on an additional 415 patients leading to approximately a 2/3 : 1/3 training to testing ratio. These results were then evaluated for discrimination and calibration. 

# Methodology

The methodology of this study included several phases which can broadly be described as patient selection, demographic and variable collection, division of patients into model development and model validation sets, preliminary model creation and fine-tuning, final model evaluation, and then creation of a logit to calculate odds.

To begin with patient selection, data was prospectively collected in four academic tertiary care hospitals with the purpose of developing and validating a multivariable logistic regression model. The four hospitals included the Medical/Surgical ICU of Memorial Sloan Kettering Cancer Center (MSKCC) in New York, NY; the City of Hope National Medical Center in Duarte, CA; the Medical ICU of The University of Texas, M.D. Anderson Cancer Center in Houston, TX; and the Mount Sinai Medical Center in New York, NY. All cancer patients admitted to the ICU were included except for those younger than 18, burn patients, and coronary patients defined by a primary diagnosis of myocardial infarction (MI). For patients with multiple admissions to the ICU, only the most recent one was used in the analysis. This led to data being collected on a total of 3005 consecutive patients. Of which many were ruled out because they did not remain after 72 hours, they had a diagnosis of rule-out MI, or they had multiple admissions, leaving us with a final sample size of 1242.

This brings us to the predictive data that was collected on selected patients. In this study, researchers collected demographic, clinical, laboratory, and physiological parameters within 1 hour of ICU admission, after 24 hours, and again after 72 hours of ICU treatment. These parameters were selected on the basis of a similar study and were decided upon prior to patient accumulation (Groeger et al.). In addition, patients were classified as one of four tumor groups: solid tumor, solid tumor with metastasis, leukemia or hematopoietic bone or peripheral stem cell transplant, and lymphoma or myeloma. Further, patients were classified as nonmetastatic if they had leukemia, bone marrow transplant, lymphoma, or myeloma. They were also classified as either medical or surgical depending on whether or not they had a surgical procedure during their hospitalization prior to ICU admission. Finally, patients were classified as medical patients if they were nonmetastatic and had undergone open lung biopsy for diagnosis of etiology of respiratory insufficiency.

Next was the division of patients into model development and model validation sets. They decided to go with a 2/3 training (n=827) to 1/3 testing (n=415) split and assigned patients to these groups randomly.

Using the training data, analysis was done to examine the distribution of variables. Hospital patient mortality in the development set was 54% with an average age of 56.8 and patients were in the hospital for an average of 10 days before ICU admission. For variables that were not collected on certain patients, a value of "No", "Never", or "Normal" was imputed if the variable was categorical, and a value within normal limits was imputed if the variable was continuous. This was done to fill in missing data without skewing results. Next, chi-square tests were done on categorical variables, and t-tests were done on continuous variables to test for the significance of each variable in predicting the status of a patient at hospital discharge. After doing these analyses, they decided that variables were eligible for entry into a logistic regression model if their p-values were less than or equal to a significance level of 0.10. In addition, some other variables were entered or omitted due to clinical evaluation based on whether they were clinically important/easy to use. The resulting list of variables is listed in table 1 of the original report (Groeger, Glassman, and Nierman et al). Next, models were evaluated by using ad hoc sensitivity analysis, specifically using stepwise logistic regression using different sets of parameters in the full model to deal with missing values. These full models had different combinations of ones that substituted "normal" for missing categorical variables, using the mean for missing continuous variables, and eliminating all continuous variables with more than one-third of values missing. This process led to a new core group of variables. After using appropriate dummy coding and transformations on certain variables, the significance of each variable was assessed in multivariate context and variables were deleted one at a time using backward elimination until all variables were significant at a level of $p \leq 0.05$. Based on clinical judgement, only variables measured at 72 h along with initial admission categorical data were entered into the model. The resulting parameters can be seen in Table 2 of the original report. Finally, the functional form of each variable was examined to determine the best way to represent it in the final model. This was done using exploratory plots and chi-square statistics to find the optimal cut points for dichotomizing continuous variables to better separate patients into different risk groups. In the end, cut points were used to dichotomize heart rate (>100 beats/min), Glasgow coma score ($\leq5$), blood urea nitrogen (BUN) (>40 mg/dl), arterial oxygen pressure/fractional inspiratory oxygen ($PaO_2$/$FiO_2$) (<250), serum bicarbonate (<20 mEq/l) and platelet count (<100 k/µl) based on clinical review. This final list of parameters is present in Table 4 of the original report.

Finally, it was important to evaluate the models using calibration and discrimination. A Hosmer-Lemeshow goodness-of-fit test was used to evaluate the fit of the logistic regression model by comparing the expected frequency of mortality based on the model to the observed frequency. This was done for both training and testing data and a chi-square value was calculated using the observed and expected frequencies. In this case, a low chi-square value and high p-value are good because this indicates the observed and expected outcomes were similar. The final coefficients in the model were then recalibrated using a shrinkage factor to enhance calibration and to help reduce the impact of over-fitting. The resulting model had a chi-squared statistic of 7.01 and corresponding $p=0.525$. Next, the area under the receiver operating characteristic (ROC) curve (AUC) was calculated to evaluate discrimination. The purpose of this was to determine the model's ability to distinguish between patients who lived and patients who died by calculating the percentage of time that the probability of mortality was higher for patients who died than patients who lived. Generally it is considered that an AUC greater than 70% is evidence of good model discrimination meaning that for at least 70% of combinations of patients who died and patients who lived, the estimated probability of death should be higher for the person who actually died. The resulting AUC was 0.809, well over the target value.

Using this final logistic regression model, the odds of a patient who has been in the ICU for 72 hours dying can be calculated using $\frac{e^{g(x)}}{1 + e^{g(x)}}$. Here, g(x) is a logit of the form $g(x) = \beta_0+\beta_i x_i$, $x = 1,...,k$ with $\beta_0$ being the constant and $\beta_ix_i$ being the estimated coefficient for the ith variable multiplied by the value of the ith variable for each term in the model. The values for the constant and coefficients can be obtained from table 4 for final calculations of g(x). This allows for an easily interpretable calculation of the chance that a patient will survive given their parameters.

# Normative Concern

While very impressive, the ability to predict the mortality of patients in the ICU comes with major ethical considerations surrounding the use of this information. The ICU is a place where confidential information is taken and potentially life-or-death scenarios occur every day. Hence, it is vital that we hold hospitals to the utmost ethics when making decisions regarding this data. 

One example of a concern is the impact it can have on patient care. As I laid out in the introduction, resources in the ICU can be sparse at times and depending on perspective, some may argue that this data could be used to better allocate resources and prioritize patients with a higher probability of being able to be helped. Another ethical dilemma is with the communication of risk. Death is a very sensitive issue and the manner in which the model's predictions are shared with patients has the potential to lead to emotional stress. However, on the other hand, could also affect the decision-making of a patient or family in a positive manner. There is also the issue of bias. Logistic regression models can potentially reinforce biases if the data disproportionately represents certain demographics. For this reason, careful consideration of demographic boundaries is vital to ensure fair treatment in the ICU. Finally, it is important to avoid over-reliance on models. There are many factors that are not taken into consideration in the model but are visible to a human. For this reason, it is important that the model is used to supplement a human's decision rather than replace it, especially in cases where the output is closer to 0.5.

All in all, it is clear that there is a pressing normative concern in how the data generated by the model is used. While models such as this have the potential to do a lot of good, they have just as much potential to do bad if used unethically.



\newpage

# References

Groeger, J S et al. “Multicenter outcome study of cancer patients admitted to the intensive care unit: a probability of mortality model.” Journal of clinical oncology : official journal of the American Society of Clinical Oncology vol. 16,2 (1998): 761-70. doi:10.1200/JCO.1998.16.2.761

Groeger, J.S., Glassman, J., Nierman, D.M. et al. Probability of mortality of critically ill cancer patients at 72 h of intensive care unit (ICU) management. Support Care Cancer 11, 686–695 (2003). https://doi.org/10.1007/s00520-003-0498-9

McCarthy, Niall, and Felix Richter. “Infographic: Many U.S. Hospitals Are Running Critically Short of ICU Beds.” Statista Daily Data, Ströer Media, 10 Dec. 2020, www.statista.com/chart/23746/icu-bed-occupancy-rates-in-us-hospital-areas/. 


